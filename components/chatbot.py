"""
Chatbot arayÃ¼zÃ¼ bileÅŸeni
"""
import streamlit as st
import os
from dotenv import load_dotenv
from openai import OpenAI
from utils.vector_store import query_collection
from config.settings import LLM_MODEL, LLM_TEMPERATURE, LLM_MAX_TOKENS, TOP_K_RESULTS


def render_chat_history():
    """
    Chat geÃ§miÅŸini gÃ¶sterir.
    """
    if len(st.session_state['chat_history']) > 0:
        st.write("ğŸ“œ **KonuÅŸma GeÃ§miÅŸi:**")
        for chat in st.session_state['chat_history']:
            with st.chat_message("user"):
                st.write(chat['question'])
            with st.chat_message("assistant"):
                st.write(chat['answer'])
        st.divider()


def render_chatbot_interface():
    """
    Ana chatbot arayÃ¼zÃ¼nÃ¼ render eder.
    """
    if 'collection' not in st.session_state:
        return
    
    st.divider()
    st.subheader("ğŸ’¬ Chatbot - Soru Sorun!")
    
    # Chat geÃ§miÅŸini gÃ¶ster
    render_chat_history()
    
    # API Key kontrolÃ¼
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key or api_key == "your_api_key_here":
        st.warning("âš ï¸ LÃ¼tfen .env dosyasÄ±na OpenAI API key'inizi ekleyin!")
        api_key = st.text_input("Veya buraya API key girin:", type="password")
    
    if api_key and api_key != "your_api_key_here":
        # Soru input
        user_question = st.text_input(
            "â“ Sorunuzu yazÄ±n:",
            placeholder="Ã–rnek: Bu veri setini aÃ§Ä±klar mÄ±sÄ±n?"
        )
        
        if user_question:
            process_user_question(user_question, api_key)


def process_user_question(user_question: str, api_key: str):
    """
    KullanÄ±cÄ± sorusunu iÅŸler ve cevap Ã¼retir.
    
    Args:
        user_question: KullanÄ±cÄ± sorusu
        api_key: OpenAI API key
    """
    with st.spinner("ğŸ¤” DÃ¼ÅŸÃ¼nÃ¼yorum..."):
        try:
            # 1. Embedding oluÅŸtur
            embedding_model = st.session_state['embedding_model']
            query_embedding = embedding_model.encode([user_question])[0]
            
            # 2. Benzer dÃ¶kÃ¼manlarÄ± bul
            collection = st.session_state['collection']
            results = query_collection(collection, query_embedding, TOP_K_RESULTS)
            
            # 3. Context oluÅŸtur
            context_docs = results['documents'][0]
            
            if not context_docs:
                st.error("âŒ Veri setinde ilgili bilgi bulunamadÄ±. LÃ¼tfen farklÄ± bir soru deneyin.")
                return
            
            context = "\n\n---\n\n".join(context_docs)
            
# 4. Prompt oluÅŸtur
            system_prompt = """Sen profesyonel bir veri analisti asistanÄ±sÄ±n. KullanÄ±cÄ±lara veri setleri hakkÄ±nda sorular sorarak yardÄ±mcÄ± oluyorsun.

GÃ¶revin:
1. Sana verilen veri setindeki bilgilere dayanarak kullanÄ±cÄ±nÄ±n sorusunu yanÄ±tlamak
2. YanÄ±tlarÄ±nÄ± aÃ§Ä±k, net ve anlaÅŸÄ±lÄ±r TÃ¼rkÃ§e ile vermek
3. EÄŸer veri setinde yeterli bilgi yoksa bunu dÃ¼rÃ¼stÃ§e belirtmek
4. MÃ¼mkÃ¼n olduÄŸunca sayÄ±sal veriler ve Ã¶rnekler vermek"""

            user_prompt = f"""AÅŸaÄŸÄ±da bir veri setinden alÄ±nmÄ±ÅŸ ilgili kayÄ±tlar bulunmaktadÄ±r. Bu kayÄ±tlara dayanarak kullanÄ±cÄ±nÄ±n sorusunu yanÄ±tla.

=== VERÄ° SETÄ° KAYITLARI ===
{context}

=== KULLANICI SORUSU ===
{user_question}

=== TALÄ°MATLAR ===
- SADECE yukarÄ±daki veri setindeki bilgileri kullan
- EÄŸer veri setinde cevap yoksa, "Bu bilgi veri setinde mevcut deÄŸil" de
- CevabÄ±nÄ± madde madde veya paragraf ÅŸeklinde dÃ¼zenle
- SayÄ±sal bilgiler varsa bunlarÄ± vurgula
- TÃ¼rkÃ§e dilbilgisi kurallarÄ±na dikkat et

Cevap:"""
            
            # 5. LLM'den cevap al
            client = OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model=LLM_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=LLM_TEMPERATURE,
                max_tokens=LLM_MAX_TOKENS,
                top_p=0.9
            )
            answer = response.choices[0].message.content
            
            # 6. CevabÄ± gÃ¶ster
            st.success("âœ… Cevap:")
            st.markdown(answer)
            
            # 7. GeÃ§miÅŸe kaydet
            st.session_state['chat_history'].append({
                'question': user_question,
                'answer': answer
            })
            
            # 8. KaynaklarÄ± gÃ¶ster
            with st.expander("ğŸ“š KullanÄ±lan Veri KaynaklarÄ± (5 en alakalÄ± kayÄ±t)"):
                for i, doc in enumerate(context_docs, 1):
                    st.markdown(f"**Kaynak {i}:**")
                    st.code(doc[:300] + ("..." if len(doc) > 300 else ""), language="text")
                    st.divider()
        
        except Exception as e:
            st.error(f"âŒ Bir hata oluÅŸtu: {str(e)}")
            st.info("ğŸ’¡ LÃ¼tfen tekrar deneyin veya farklÄ± bir soru sorun.")