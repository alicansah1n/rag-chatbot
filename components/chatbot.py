"""
Chatbot arayÃ¼zÃ¼ bileÅŸeni
"""
import streamlit as st
import os
from openai import OpenAI
from utils.vector_store import query_collection
from config.settings import LLM_MODEL, LLM_TEMPERATURE, LLM_MAX_TOKENS, TOP_K_RESULTS


def render_chat_history():
    """Chat geÃ§miÅŸini gÃ¶sterir."""
    if len(st.session_state['chat_history']) > 0:
        st.write("ðŸ“œ **KonuÅŸma GeÃ§miÅŸi:**")
        for chat in st.session_state['chat_history']:
            with st.chat_message("user"):
                st.write(chat['question'])
            with st.chat_message("assistant"):
                st.write(chat['answer'])
        st.divider()


def get_api_key():
    """
    API key'i alÄ±r (secrets veya environment'tan).
    
    Returns:
        str: API key veya None
    """
    # Ã–nce Streamlit secrets'tan dene
    try:
        return st.secrets["OPENAI_API_KEY"]
    except:
        pass
    
    # Sonra environment variable'dan dene
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key and api_key != "your_api_key_here":
        return api_key
    
    return None


def render_chatbot_interface():
    """Ana chatbot arayÃ¼zÃ¼nÃ¼ render eder."""
    if 'collection' not in st.session_state:
        st.info("âš ï¸ LÃ¼tfen Ã¶nce veriyi iÅŸleyin ve hazÄ±rlayÄ±n.")
        return
    
    st.divider()
    st.subheader("ðŸ’¬ AI Chatbot - Veri Setiniz HakkÄ±nda Soru Sorun")
    
    # Chat geÃ§miÅŸini gÃ¶ster
    render_chat_history()
    
    # API Key kontrolÃ¼
    api_key = get_api_key()
    
    if not api_key:
        st.error("âŒ OpenAI API key bulunamadÄ±!")
        st.info("ðŸ’¡ LÃ¼tfen Streamlit Secrets'a veya .env dosyasÄ±na API key'inizi ekleyin.")
        api_key = st.text_input("Veya buraya API key girin:", type="password", key="api_key_input")
    
    if api_key:
        # Soru input
        user_question = st.text_input(
            "â“ Sorunuzu yazÄ±n:",
            placeholder="Ã–rnek: Veri setini detaylÄ± aÃ§Ä±klar mÄ±sÄ±n?",
            key="user_question_input"
        )
        
        col1, col2 = st.columns([1, 5])
        with col1:
            submit_button = st.button("ðŸš€ GÃ¶nder", type="primary")
        
        if submit_button and user_question:
            process_user_question(user_question, api_key)
        elif submit_button and not user_question:
            st.warning("âš ï¸ LÃ¼tfen bir soru yazÄ±n!")


def process_user_question(user_question: str, api_key: str):
    """
    KullanÄ±cÄ± sorusunu iÅŸler ve cevap Ã¼retir.
    
    Args:
        user_question: KullanÄ±cÄ± sorusu
        api_key: OpenAI API key
    """
    with st.spinner("ðŸ¤” Analiz ediyorum..."):
        try:
            # Toplam kayÄ±t sayÄ±sÄ±nÄ± al
            total_records = len(st.session_state.get('documents', []))
            
            # 1. Embedding oluÅŸtur
            embedding_model = st.session_state['embedding_model']
            query_embedding = embedding_model.encode([user_question])[0]
            
            # 2. Benzer dÃ¶kÃ¼manlarÄ± bul
            collection = st.session_state['collection']
            results = query_collection(collection, query_embedding, TOP_K_RESULTS)
            
            # 3. Context oluÅŸtur
            context_docs = results['documents'][0]
            
            if not context_docs:
                st.error("âŒ Veri setinde ilgili bilgi bulunamadÄ±.")
                st.info("ðŸ’¡ FarklÄ± bir soru deneyin veya daha genel bir soru sorun.")
                return
            
            # TÃ¼m bulunan kayÄ±tlarÄ± kullan (TOP_K kadar)
            context = "\n\n---\n\n".join(context_docs)
            
            # 4. Prompt oluÅŸtur
            system_prompt = """Sen uzman bir veri analisti ve AI asistanÄ±sÄ±n. GÃ¶revin:

1. Verilen veri setindeki bilgilere dayanarak kullanÄ±cÄ±nÄ±n sorusunu yanÄ±tlamak
2. YanÄ±tlarÄ±nÄ± aÃ§Ä±k, net ve profesyonel TÃ¼rkÃ§e ile sunmak
3. SayÄ±sal analizler ve istatistikler sunmak
4. Veri setinde yeterli bilgi yoksa dÃ¼rÃ¼stÃ§e belirtmek
5. GerektiÄŸinde Ã¶rneklerle aÃ§Ä±klamak

YanÄ±t formatÄ±:
- KÄ±sa ve Ã¶z bir Ã¶zet ile baÅŸla
- DetaylÄ± analiz ve sayÄ±sal veriler sun
- Madde madde veya paragraf halinde dÃ¼zenle
- Profesyonel ama anlaÅŸÄ±lÄ±r bir dil kullan"""

            user_prompt = f"""VERÄ° SETÄ° BÄ°LGÄ°LERÄ°:
- Toplam kayÄ±t sayÄ±sÄ±: {total_records:,} satÄ±r
- Analiz iÃ§in kullanÄ±lan Ã¶rnek: {len(context_docs)} en alakalÄ± kayÄ±t

=== VERÄ° SETÄ° Ã–RNEKLERÄ° (En AlakalÄ± {len(context_docs)} KayÄ±t) ===
{context}

=== KULLANICI SORUSU ===
{user_question}

=== Ã–NEMLÄ° TALÄ°MATLAR ===
âœ“ EÄŸer soru "kaÃ§ satÄ±r", "toplam kayÄ±t", "veri seti bÃ¼yÃ¼klÃ¼ÄŸÃ¼" gibi GENEL bilgiler hakkÄ±ndaysa:
  â†’ Toplam kayÄ±t sayÄ±sÄ±nÄ± ({total_records:,}) kullan
  â†’ Veri setinin genel Ã¶zelliklerinden bahset

âœ“ EÄŸer soru spesifik bir analiz, filtreleme veya hesaplama gerektiriyorsa:
  â†’ YukarÄ±daki Ã¶rnek kayÄ±tlara dayanarak analiz yap
  â†’ "Analiz edilen {len(context_docs)} kayÄ±t Ã¼zerinden..." ÅŸeklinde belirt

âœ“ Ä°statistiksel bilgiler varsa bunlarÄ± vurgula
âœ“ SayÄ±sal verileri tablolar veya maddeler halinde sun
âœ“ Veri setinde cevap yoksa aÃ§Ä±kÃ§a belirt
âœ“ TÃ¼rkÃ§e dilbilgisi kurallarÄ±na Ã¶zen gÃ¶ster

Cevap:"""
            
            # 5. LLM'den cevap al
            client = OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model=LLM_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=LLM_TEMPERATURE,
                max_tokens=LLM_MAX_TOKENS,
                top_p=0.9
            )
            answer = response.choices[0].message.content
            
            # 6. CevabÄ± gÃ¶ster
            st.success("âœ… **Analiz Sonucu:**")
            st.markdown(answer)
            
            # 7. GeÃ§miÅŸe kaydet
            st.session_state['chat_history'].append({
                'question': user_question,
                'answer': answer
            })
            
            # 8. Meta bilgiler
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ðŸ¤– Model", LLM_MODEL)
            with col2:
                st.metric("ðŸ“Š Analiz Edilen", f"{len(context_docs)}/{total_records:,}")
            with col3:
                st.metric("ðŸ’¾ Toplam Veri", f"{total_records:,} satÄ±r")
            
            # 9. KaynaklarÄ± gÃ¶ster
            with st.expander(f"ðŸ“š KullanÄ±lan Veri KaynaklarÄ± ({min(len(context_docs), 5)} Ã¶rnek)"):
                for i, doc in enumerate(context_docs[:5], 1):
                    st.markdown(f"**ðŸ“„ Kaynak {i}:**")
                    st.code(doc[:400] + ("..." if len(doc) > 400 else ""), language="text")
                    if i < 5:
                        st.divider()
        
        except Exception as e:
            st.error(f"âŒ Bir hata oluÅŸtu: {str(e)}")
            
            # DetaylÄ± hata mesajÄ± (debug iÃ§in)
            if "API key" in str(e) or "api_key" in str(e):
                st.info("ðŸ’¡ API key'inizi kontrol edin. Streamlit Secrets veya .env dosyasÄ±nda doÄŸru tanÄ±mlandÄ±ÄŸÄ±ndan emin olun.")
            elif "rate limit" in str(e).lower():
                st.info("ðŸ’¡ OpenAI rate limit aÅŸÄ±ldÄ±. BirkaÃ§ saniye bekleyip tekrar deneyin.")
            else:
                st.info("ðŸ’¡ LÃ¼tfen tekrar deneyin veya farklÄ± bir soru sorun.")
            
            # Hata detayÄ± (geliÅŸtirme modu iÃ§in)
            with st.expander("ðŸ” Hata DetayÄ± (GeliÅŸtiriciler iÃ§in)"):
                st.code(str(e))